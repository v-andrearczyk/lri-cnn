{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from functools import partial\n",
    "import multiprocessing.pool\n",
    "from six.moves import xrange \n",
    "import tensorflow as tf\n",
    "import math\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from utils import *\n",
    "from create_synthetic_dataset import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def placeholder_inputs():\n",
    "    \"\"\"Generate placeholder variables to represent the input tensors.\n",
    "    Returns:\n",
    "    images_placeholder: Images placeholder.\n",
    "    labels_placeholder: Labels placeholder.\n",
    "    \"\"\"\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(None,\n",
    "                                                         model.IM_SIZE,\n",
    "                                                         model.IM_SIZE,\n",
    "                                                         model.IM_SIZE,\n",
    "                                                         model.CHANNELS))\n",
    "    labels_placeholder = tf.placeholder(tf.int64, shape=(None))\n",
    "    return images_placeholder, labels_placeholder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/vincent/repos/sh01/utils.py(193)copy_template()\n",
      "-> cube_size = cube.shape[0]\n",
      "(Pdb) cube\n",
      "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]])\n",
      "(Pdb) cube.shape\n",
      "(32, 32, 32)\n",
      "(Pdb) print(t)\n",
      "[[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 1.55053960e-02 1.59719145e-01\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.05848995e-01\n",
      "   6.88422095e-02 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.32131362e-02\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 2.88309967e-01 8.43856670e-01\n",
      "   2.32629883e-01 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 1.53476722e-02 4.96298219e-01 9.65668733e-01\n",
      "   4.95573737e-01 6.82242473e-04 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 8.82767740e-02 2.95136138e-01\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.45686699e-01\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 5.09494382e-02 5.67460753e-01\n",
      "   2.84881035e-01 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 3.06173062e-01 9.59520430e-01\n",
      "   7.65966568e-01 6.50657970e-02 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 3.58745384e-01 1.00000000e+00\n",
      "   7.29567570e-01 3.52902080e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.50479013e-01\n",
      "   0.00000000e+00 7.34772890e-02 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 3.79838171e-01\n",
      "   3.05096626e-01 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 8.09659616e-04 4.38212719e-01 1.00000000e+00\n",
      "   8.25408698e-01 1.24711952e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 2.27711306e-01 1.00000000e+00\n",
      "   1.00000000e+00 5.98606507e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 5.26105445e-01\n",
      "   1.00000000e+00 1.00000000e+00 1.62423475e-01]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.98534923e-02\n",
      "   4.30534364e-01 2.11126809e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.98899501e-01\n",
      "   5.93626462e-02 7.09930095e-02 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 1.56747825e-01 8.04509577e-01\n",
      "   8.93479903e-01 6.52487604e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.66663315e-01\n",
      "   1.00000000e+00 8.56321352e-01 7.95937659e-02]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   6.93465506e-01 6.63809586e-01 9.59995605e-02]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   1.64140662e-01 1.50184126e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   1.26772802e-02 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.12380521e-01\n",
      "   4.84088880e-01 1.47005170e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   5.71622887e-01 3.62012874e-01 1.20826967e-02]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   1.00996293e-01 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 8.14992910e-03 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   5.74277697e-03 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "(Pdb) print(t.shape)\n",
      "(7, 7, 7)\n",
      "(Pdb) print(pos)\n",
      "[21  0  3]\n"
     ]
    }
   ],
   "source": [
    "X,y = create_synthetic_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the model definition:\n",
    "import s_lri_model as model\n",
    "#import s_lri_deep2_model as model\n",
    "#import sse_lri_model as model\n",
    "#import bispectrum_lri_model as model\n",
    "#import g_lri_model as model\n",
    "#import g_ri_model as model\n",
    "#import conv_separable_model as model\n",
    "#import g_lri_sep_model as model\n",
    "\n",
    "## All parameters for training\n",
    "is_shconv = True # To compare with a normal CNN (shconv=False) \n",
    "is_trainable = True # To test freezing the conv weights\n",
    "is_hn=True # If false: polar-separable\n",
    "is_augment=False # Right angle rotation augmentation at training\n",
    "M = 4 # number of orientations (only needed for S-LRI). 1, 4, 24 or 72\n",
    "nf1 = 2 # number of filters in first layer\n",
    "batch_size = 16\n",
    "stride = 1 \n",
    "lr = 1e-3\n",
    "max_steps = 50000\n",
    "degreeMax = 1 # maxmum degree of the SHs\n",
    "ksize = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_test_acc = []\n",
    "for _ in xrange(10):\n",
    "    n_class = 2\n",
    "    tf.reset_default_graph()\n",
    "    # Placeholders    \n",
    "    xph, yph = placeholder_inputs()\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "    # Construct model and optimizer\n",
    "    pred = model.build_model(X = xph,\n",
    "                            batch_size = batch_size,\n",
    "                            n_class = n_class,\n",
    "                            nf1 = nf1,\n",
    "                            ksize = ksize,\n",
    "                            stride = stride,\n",
    "                            is_trainable = is_trainable,\n",
    "                            degreeMax = degreeMax,\n",
    "                            is_shconv = is_shconv,\n",
    "                            is_hn = is_hn,\n",
    "                            M = M\n",
    "                            )\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=yph))\n",
    "\n",
    "    # Evaluation criteria\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), yph)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    # Optimizer\n",
    "    optim = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.99, beta2=0.9999)\n",
    "    grads_and_vars = optim.compute_gradients(loss)\n",
    "    train_op = optim.apply_gradients(grads_and_vars)\n",
    "\n",
    "\n",
    "    # Configure tensorflow session\n",
    "    init_global = tf.global_variables_initializer()\n",
    "    init_local = tf.local_variables_initializer()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.log_device_placement = False\n",
    "\n",
    "    sess = tf.Session(config=config)\n",
    "    sess.run([init_global, init_local])\n",
    "\n",
    "    # shuffle           \n",
    "    np.random.seed(0)\n",
    "    idx = np.arange(0,len(X))\n",
    "    np.random.shuffle(idx)\n",
    "    X_shuf = X[idx]\n",
    "    y_shuf = y[idx]\n",
    "    \n",
    "    # Split 4/5 train 1/5 test\n",
    "    ntest = int(X_shuf.shape[0]/5)\n",
    "    ntrain = int(X_shuf.shape[0]*4/5)\n",
    "    X_train, X_test = X_shuf[:ntrain], X_shuf[:ntest]\n",
    "    y_train, y_test = y_shuf[:ntrain], y_shuf[:ntest]\n",
    "    \n",
    "    print('X_train shape:',X_train.shape, 'X_test shape:',X_test.shape, 'y_train shape:',y_train.shape, 'y_test shape:',y_test.shape)\n",
    "\n",
    "    print('Starting training loop...')\n",
    "    for step in xrange(max_steps):\n",
    "        Xb, Yb = next_batch(batch_size, X_train, y_train, is_augment)\n",
    "        feed_dict = {xph: Xb, yph: Yb, learning_rate: lr}\n",
    "        __, loss_train, acc_train = sess.run([train_op, loss, accuracy], feed_dict=feed_dict)\n",
    "\n",
    "        if (step) % 5000 == 0 and step!=0 or (step + 1) == max_steps:                \n",
    "            print('Step %d'%(step))\n",
    "            print('Training Data Eval:')\n",
    "            print (\"accuracy training: \" + \"{:.5f}\".format(acc_train))\n",
    "            print (\"loss training: \" + \"{:.5f}\".format(loss_train))\n",
    "\n",
    "            # Training Data Eval:\n",
    "            ############\n",
    "            nb_train_steps = int(math.ceil(float(y_train.shape[0])/(batch_size)))\n",
    "            acc_train_all=0.\n",
    "            for step_t in xrange(nb_train_steps):\n",
    "                Xt=X_train[step_t*batch_size:(step_t+1)*batch_size]\n",
    "                Yt=y_train[step_t*batch_size:(step_t+1)*batch_size]\n",
    "                feed_dict = {xph: Xt, yph: Yt}\n",
    "                accuracy_,pred_ = sess.run([accuracy,pred], feed_dict=feed_dict)\n",
    "                acc_train_all += accuracy_*Xt.shape[0]\n",
    "            acc_train_all=acc_train_all/X_train.shape[0]\n",
    "            print (\"accuracy training: \" + \"{:.5f}\".format(acc_train_all))\n",
    "\n",
    "            print('Test Data Eval:')\n",
    "            ############\n",
    "            nb_test_steps = int(math.ceil(float(y_test.shape[0])/(batch_size)))\n",
    "            acc_test=0.\n",
    "            for step_t in xrange(nb_test_steps):\n",
    "                Xt=X_test[step_t*batch_size:(step_t+1)*batch_size]\n",
    "                Yt=y_test[step_t*batch_size:(step_t+1)*batch_size]\n",
    "                feed_dict = {xph: Xt, yph: Yt}\n",
    "                accuracy_,pred_ = sess.run([accuracy,pred], feed_dict=feed_dict)\n",
    "                acc_test += accuracy_*Xt.shape[0]\n",
    "            acc_test=acc_test/X_test.shape[0]\n",
    "            print (\"accuracy test: \" + \"{:.5f}\".format(acc_test))    \n",
    "    list_test_acc.append(acc_test)\n",
    "    print('list_test_acc: ',list_test_acc, np.mean(list_test_acc))\n",
    "    sess.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
